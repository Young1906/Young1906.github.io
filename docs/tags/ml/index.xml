<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ml on iamtu</title>
    <link>https://iamtu.dev/tags/ml/</link>
    <description>Recent content in ml on iamtu</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 22 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://iamtu.dev/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Learning to solve heat equation</title>
      <link>https://iamtu.dev/posts/heat/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://iamtu.dev/posts/heat/</guid>
      <description>(note) Editting note TODO:
Motivation section Introduction to heat equation BTCS scheme PINN Theory? Coding Citation? Compare results with close-form solution Proof read? TLDR Surveying numerical methods (finite difference methods) and physics-informed neural networks to solve a 1D heat equation. This post was heavily inspired by:
(Book) Partial Differential Equations for Scientists and Engineers - Standley J. Farlow for deriving closed-form solution. (Article) Finite-Difference Approximations to the Heat Equation (Course) ETH Zurich | Deep Learning for Scientific Computing 2023 for Theory and Implementation of Physics-Informed Neural Network.</description>
    </item>
    
    <item>
      <title>Expectation Maximization - EM</title>
      <link>https://iamtu.dev/posts/em/</link>
      <pubDate>Wed, 08 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://iamtu.dev/posts/em/</guid>
      <description>Problem Given a statistical model \(P(\boldsymbol{X}, \boldsymbol{Z} | \boldsymbol{\theta})\), which generate set of observations \(\boldsymbol{X}\), where \(\boldsymbol{Z}\) is a latent variable and unknow parameter vector \(\boldsymbol{\theta}\). The goal is to find \(\boldsymbol{\theta}\) that maximize the marginal likelihood:
$$ \mathcal{L}(\boldsymbol{\theta}; \boldsymbol{X}) = P(\boldsymbol{X} | \boldsymbol{\theta}) = \int_{\boldsymbol{Z}}P(\boldsymbol{X}, \boldsymbol{Z} | \boldsymbol{\theta})d\boldsymbol{Z} $$
As an example for this type of problem, there are two (unfair) coin A and B with probability of head for each coin is \(p_A(H) = p \text{ and } p_B(H) = q\).</description>
    </item>
    
  </channel>
</rss>
